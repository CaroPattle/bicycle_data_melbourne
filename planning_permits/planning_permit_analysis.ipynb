{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb93586",
   "metadata": {},
   "source": [
    "# Planning Permits Analysis\n",
    "\n",
    "This analysis uses data from https://discover.data.vic.gov.au/dataset?q=planning%20permits.\n",
    "\n",
    "\n",
    "'The Victorian Building Authority (VBA) collects information from building surveyors on the number, value and type of building permits issued each month as part of its functions under the Building Act 1993'\n",
    " \n",
    "Firstly there is also a building permit activity monthly summary dataset which has been updated to April 2021 (https://discover.data.vic.gov.au/dataset/building-permit-activity-monthly-summaries). This is an aggregated dataset which includes data visualisations which track building use, costs, \n",
    "\n",
    "\n",
    "The summary dataset aggregates data from separate annual datesets which run from to 2020 (https://discover.data.vic.gov.au/dataset/building-permit-activity-data-2020). ** up to 2021 on building vic autority (VBA) site ** Within these datasets, each record or row represents a single permit.\n",
    "\n",
    "These annual datasets include over 40 pieces of information per record, such as details of what is to be built (or demolished),the intended use of the building, the ownership sector, and the building costs. \n",
    "\n",
    "In addition, the location of the building can be viewed down to the street name level, with postal codes, suburbs and regions also included.\n",
    "\n",
    "A comprehensive data dictionary for the building permit datsets can be found on the VBA site here (https://www.vba.vic.gov.au/about/data), as well as a detailed data quality statement PDF which includes clear summaries about what the data represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a1a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f0d4f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15468/2351309615.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'pyxlsb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m                 )\n\u001b[0;32m    298\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         raise ValueError(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1129\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \"\"\"\n\u001b[0;32m    474\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"openpyxl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    380\u001b[0m         )\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workbook_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             self.handles = get_handle(\n\u001b[0m\u001b[0;32m    383\u001b[0m                 \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"method\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         return IOArgs(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readall_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readall_chunked\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    573\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m                 \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mIncompleteRead\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdetect\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# VBA DataVic data, hosted on VBA website\n",
    "dataset_urls = {\n",
    "    '2021':'https://www.vba.vic.gov.au/__data/assets/excel_doc/0004/143572/VBA-DataVic-Building-Permits-2021.xlsx',\n",
    "    '2020':'https://www.vba.vic.gov.au/__data/assets/file/0012/110028/VBA-DataVic-Building-Permits-2020.xlsb',\n",
    "    '2019':'https://www.vba.vic.gov.au/__data/assets/file/0015/103515/VBA-DataVic-Building-Permits-2019.xlsb'\n",
    "}\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for dataset in dataset_urls:\n",
    "    if dataset_urls[dataset].endswith('xlsb'):\n",
    "        # to read xlsb, you need to install pyxlsb using pip at command prompt (pip install pyxlsb)\n",
    "        dfs[dataset] = pd.read_excel(dataset_urls[dataset],sheet_name=1,engine='pyxlsb') \n",
    "    else:\n",
    "        dfs[dataset] = pd.read_excel(dataset_urls[dataset],sheet_name=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the datasets contain the same number of variables?\n",
    "for year in dfs:\n",
    "    print(f'{year}: {len(dfs[year].columns)}')\n",
    "    \n",
    "len(dfs['2019'].columns)== len(dfs['2020'].columns) == len(dfs['2021'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2019 dataset has more variables than the subsequent years; let's come back to 2019 \n",
    "\n",
    "# First, let's check that the 37 variables in the 2020 and 2021 datasets are the same\n",
    "\n",
    "for i,assertion in enumerate(dfs['2020'].columns == dfs['2021'].columns):\n",
    "    if assertion == False:\n",
    "        print(f\"Year  Mis-matched column\")\n",
    "        for year in ['2020','2021']:\n",
    "            print(f'{year}: {dfs[year].columns[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column 'BASIS_BCA' is mis-spelt in the 2020 dataset; let's correct that\n",
    "dfs['2020'].rename(columns={'BASIS_ BCA':'BASIS_BCA'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e59f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's confirm that's fixed now:\n",
    "for i,assertion in enumerate(dfs['2020'].columns == dfs['2021'].columns):\n",
    "    if assertion == False:\n",
    "        print(f\"Year  Mis-matched column\")\n",
    "        for year in ['2020','2021']:\n",
    "            print(f'{year}: {dfs[year].columns[i]}')\n",
    "\n",
    "# yes, all good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d9492",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's look at the 2019 and 2020 variables\n",
    "print(dfs['2019'].columns)\n",
    "print(dfs['2020'].columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb810b0e",
   "metadata": {},
   "source": [
    "The 2019 variables are in a different order, and spelt differently.\n",
    "\n",
    "To determine how to proceed, lets compare\n",
    "\n",
    "- The VBA data dictonary (last modified 2015, at time of writing)\n",
    "- The 2019 dataset columns\n",
    "- The consolidated 2020/21 columns (following space correction of BASIS_BCA variable name, above)\n",
    "- A combined proposed plain text variable name without special characters \n",
    "\n",
    "| ID | Data dictionary        |          2019          |               2020/21               | Proposed variable name        |\n",
    "|----|------------------------|:----------------------:|:-----------------------------------:|-------------------------------|\n",
    "| 1  | permit_stage_number    | permit_stage_number    | permit_stage_number                 | Permit Stage Number           |\n",
    "| 2  | permit_date            | permit_date            | permit_date                         | Permit Date                   |\n",
    "| 3  | BASIS_Month_Y          | BASIS_Month_Y          | BASIS_Month_Y                       | Year                          |\n",
    "| 4  | BASIS_Month_M          | BASIS_Month_M          | BASIS_Month_M                       | Month                         |\n",
    "| 5  | Reported_Levy_amount   | Reported_Levy_amount   |                                     | Reported Levy Amount          |\n",
    "| 6  | Calculated_Levy_amount | Calculated_Levy_amount |                                     | Calculated Levy Amount        |\n",
    "| 7  |                        |                        | Original_Levy_Paid__c               | Original Levy Paid            |\n",
    "| 8  | Reported_Cost_of_works | Reported_Cost_of_works | Reported_Cost_of_works              | Reported Cost Of Works        |\n",
    "| 9  | Site_street            | Site_street            | site_street_name__c                 | Site Street                   |\n",
    "| 10 | Site_suburb            | Site_suburb            | site_town_suburb__c                 | Site Suburb                   |\n",
    "| 11 | site_pcode             | site_pcode             | site_postcode__c                    | Site Postcode                 |\n",
    "| 12 | Municipal name         | Municipal Name         | Site_Municipality                   | Municipal Name                |\n",
    "| 13 | Municipal full name    | Municipal Full Name    | Municipal Full Name                 | Municipal Full Name           |\n",
    "| 14 | Region                 | Region                 | Region                              | Region                        |\n",
    "| 15 | Sub_Region             | Sub_Region             | Sub_Region                          | Sub Region                    |\n",
    "| 16 | Sub_Region1            | Sub_Region1            | Sub_Region1                         | Sub Region1                   |\n",
    "| 17 | Allotment_Area         | Allotment_Area         | Allotment_Area__c                   | Allotment Area                |\n",
    "| 18 | Builder_suburb         | Builder_suburb         | Builder_Town_Suburb__c              | Builder Suburb                |\n",
    "| 19 | Builder_state          | Builder_state          | Builder_State__c                    | Builder State                 |\n",
    "| 20 | Builder_pcode          | Builder_pcode          | Builder_Postcode__c                 | Builder Postcode              |\n",
    "| 21 | Material_Code_Floor    | Material_Code_Floor    | Floor_Material__c                   | Material Code Floor           |\n",
    "| 22 | Material_Code_Frame    | Material_Code_Frame    | Frame_Material__c                   | Material Code Frame           |\n",
    "| 23 | Material_Code_Roof     | Material_Code_Roof     | Roof_Cladding_Material__c           | Material Code Roof            |\n",
    "| 24 | Material_Code_Walls    | Material_Code_Walls    | External_Wall_Material__c           | Material Code Walls           |\n",
    "| 25 | dwellings_before_work  | dwellings_before_work  | Number_of_Existing_Dwellings__c     | Existing Dwellings            |\n",
    "| 26 | dwellings_after_work   | dwellings_after_work   | Number_of_New_Dwellings__c          | New Dwellings                 |\n",
    "| 27 | Number_of_storeys      | Number_of_storeys      | Number_of_Storeys__c                | Storeys                       |\n",
    "| 28 | number_demolished      | number_demolished      | Number_of_Dwellings_Demolished__c   | Dwellings Demolished          |\n",
    "| 29 | Floor_area             | Floor_area             | Total_Floor_Area__c                 | Floor Area                    |\n",
    "| 30 | Multiple_Dwellings     | Multiple_Dwellings     |                                     | Multiple Dwellings            |\n",
    "| 31 | cost_of_works_domestic | cost_of_works_domestic |                                     | Cost Of Works Domestic        |\n",
    "| 32 | Permit_app_date        | Permit_app_date        | Building_Permit_Application_Date__c | Permit Application Date       |\n",
    "| 33 | BACV_applicable_flag   | BACV_applicable_flag   |                                     | BACV Applicable Flag          |\n",
    "| 34 | Calculated_levy_BACV   | Calculated_levy_BACV   |                                     | Calculated Levy BACV          |\n",
    "| 35 |                        |                        | DBDRV Levy                          | DBDRV Levy                    |\n",
    "| 36 | solar_hot_water        | solar_hot_water        | Solar_Hot_Water_Indicator__c        | Solar Hot Water               |\n",
    "| 37 | rainwater_tank         | rainwater_tank         | Rainwater_Tank_Indicator__c         | Rainwater Tank                |\n",
    "| 38 | est_cost_project       | est_cost_project       | Total_Estimated_Cost_of_Works__c    | Total Estimated Cost of Works |\n",
    "| 39 | BASIS_Zone             | BASIS_Building_Use     | BASIS_Building_Use                  | BASIS Building Use            |\n",
    "| 40 | BASIS_NOW              | BASIS_NOW              | BASIS_NOW                           | BASIS NOW                     |\n",
    "| 41 | BASIS_BCA              | BASIS_BCA              | BASIS_BCA                           | BASIS BCA                     |\n",
    "| 42 | BASIS_OwnershipSector  | BASIS_OwnershipSector  | BASIS_Ownership_Sector              | BASIS Ownership Sector        |\n",
    "| 43 | BASIS_OwnerBuilder     | BASIS_OwnerBuilder     | BASIS_Owner_Builder                 | BASIS Owner Builder           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73ce50",
   "metadata": {},
   "source": [
    "Through this comparison it is apparent that,\n",
    "\n",
    "- The 2019 dataset is mostly in accord with the data dictionary\n",
    "- The data dictionary variable 'BASIS_ZONE' appears to have been framed as 'BASIS_NOW' in the 2019, 2020 and 2021 datasets\n",
    "- Reported and calculated levy amounts are not recorded in 2020/21; there was an original levy paid variable instead\n",
    "- Multiple dwellings and domestic cost of works was not recorded in 2020/21\n",
    "- The BACV applicable flag and calculated levy were not recorded in 2020/21; there is however a 'DBDRV Levy'\n",
    "\n",
    "Now we will ensure that each year shares the same variables and names, with missing values where these variables do not directly correspond, as per the proposed variable names in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096725a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create columns which did not exist with null values\n",
    "dfs['2019']['Original Levy Paid'] = np.nan\n",
    "dfs['2019']['DBDRV Levy'] = np.nan\n",
    "for year in ['2020','2021']:\n",
    "    dfs[year]['Reported Levy Amount'] = np.nan\n",
    "    dfs[year]['Calculated Levy Amount'] = np.nan\n",
    "    dfs[year]['Multiple Dwellings'] = np.nan\n",
    "    dfs[year]['Cost Of Works Domestic'] = np.nan\n",
    "    dfs[year]['BACV Applicable Flag'] = np.nan\n",
    "    dfs[year]['Calculated Levy BACV'] = np.nan\n",
    "\n",
    "# rename columns\n",
    "rename_2019_to_proposed = {'permit_stage_number':'Permit Stage Number','permit_date':'Permit Date','BASIS_Month_Y':'Year','BASIS_Month_M':'Month','Reported_Levy_amount':'Reported Levy Amount','Calculated_Levy_amount':'Calculated Levy Amount','Reported_Cost_of_works':'Reported Cost Of Works','Site_street':'Site Street','Site_suburb':'Site Suburb','site_pcode':'Site Postcode','Municipal Name':'Municipal Name','Municipal Full Name':'Municipal Full Name','Region':'Region','Sub_Region':'Sub Region','Sub_Region1':'Sub Region1','Allotment_Area':'Allotment Area','Builder_suburb':'Builder Suburb','Builder_state':'Builder State','Builder_pcode':'Builder Postcode','Material_Code_Floor':'Material Code Floor','Material_Code_Frame':'Material Code Frame','Material_Code_Roof':'Material Code Roof','Material_Code_Walls':'Material Code Walls','dwellings_before_work':'Existing Dwellings','dwellings_after_work':'New Dwellings','Number_of_storeys':'Storeys','number_demolished':'Dwellings Demolished','Floor_area':'Floor Area','Multiple_Dwellings':'Multiple Dwellings','cost_of_works_domestic':'Cost Of Works Domestic','Permit_app_date':'Permit Application Date','BACV_applicable_flag':'BACV Applicable Flag','Calculated_levy_BACV':'Calculated Levy BACV','solar_hot_water':'Solar Hot Water','rainwater_tank':'Rainwater Tank','est_cost_project':'Total Estimated Cost of Works','BASIS_Building_Use':'BASIS Building Use','BASIS_NOW':'BASIS NOW','BASIS_BCA':'BASIS BCA','BASIS_OwnershipSector':'BASIS Ownership Sector','BASIS_OwnerBuilder':'BASIS Owner Builder'}\n",
    "rename_202x_to_proposed = {'permit_stage_number':'Permit Stage Number','permit_date':'Permit Date','BASIS_Month_Y':'Year','BASIS_Month_M':'Month','Original_Levy_Paid__c':'Original Levy Paid','Reported_Cost_of_works':'Reported Cost Of Works','site_street_name__c':'Site Street','site_town_suburb__c':'Site Suburb','site_postcode__c':'Site Postcode','Site_Municipality':'Municipal Name','Municipal Full Name':'Municipal Full Name','Region':'Region','Sub_Region':'Sub Region','Sub_Region1':'Sub Region1','Allotment_Area__c':'Allotment Area','Builder_Town_Suburb__c':'Builder Suburb','Builder_State__c':'Builder State','Builder_Postcode__c':'Builder Postcode','Floor_Material__c':'Material Code Floor','Frame_Material__c':'Material Code Frame','Roof_Cladding_Material__c':'Material Code Roof','External_Wall_Material__c':'Material Code Walls','Number_of_Existing_Dwellings__c':'Existing Dwellings','Number_of_New_Dwellings__c':'New Dwellings','Number_of_Storeys__c':'Storeys','Number_of_Dwellings_Demolished__c':'Dwellings Demolished','Total_Floor_Area__c':'Floor Area','Building_Permit_Application_Date__c':'Permit Application Date','DBDRV Levy':'DBDRV Levy','Solar_Hot_Water_Indicator__c':'Solar Hot Water','Rainwater_Tank_Indicator__c':'Rainwater Tank','Total_Estimated_Cost_of_Works__c':'Total Estimated Cost of Works','BASIS_Building_Use':'BASIS Building Use','BASIS_NOW':'BASIS NOW','BASIS_BCA':'BASIS BCA','BASIS_Ownership_Sector':'BASIS Ownership Sector','BASIS_Owner_Builder':'BASIS Owner Builder'}\n",
    "\n",
    "dfs['2019'].rename(columns = rename_2019_to_proposed,inplace=True)\n",
    "dfs['2020'].rename(columns = rename_202x_to_proposed,inplace=True)\n",
    "dfs['2021'].rename(columns = rename_202x_to_proposed,inplace=True)\n",
    "\n",
    "# order columns\n",
    "columns = ['Permit Stage Number','Permit Date','Year','Month','Reported Levy Amount','Calculated Levy Amount','Original Levy Paid','Reported Cost Of Works','Site Street','Site Suburb','Site Postcode','Municipal Name','Municipal Full Name','Region','Sub Region','Sub Region1','Allotment Area','Builder Suburb','Builder State','Builder Postcode','Material Code Floor','Material Code Frame','Material Code Roof','Material Code Walls','Existing Dwellings','New Dwellings','Storeys','Dwellings Demolished','Floor Area','Multiple Dwellings','Cost Of Works Domestic','Permit Application Date','BACV Applicable Flag','Calculated Levy BACV','DBDRV Levy','Solar Hot Water','Rainwater Tank','Total Estimated Cost of Works','BASIS Building Use','BASIS NOW','BASIS BCA','BASIS Ownership Sector','BASIS Owner Builder']\n",
    "for year in ['2019','2020','2021']:\n",
    "    dfs[year] = dfs[year][columns]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the year variable correctly indexes each year, and year is not missing\n",
    "# This is important for when we join these seperate datasets to ensure they can be \n",
    "# correctly distinguished\n",
    "years = ['2019','2020','2021']\n",
    "for year in ['2019','2020','2021']:\n",
    "    print(f'\\n{year}')\n",
    "    print(dfs[year]['Year'].describe())\n",
    "    print(f'Missing year: {dfs[year][\"Year\"].isna().sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa980868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the data (noted in exploratory analysis below), it looks like solar hot water and rain water indicators are missing for 2020/21\n",
    "# looking at the data, its clear that this is because for these years they were coded not as 0/1 binary indicators\n",
    "# (as per data dictionary), but instead as N/Y string indicators; this impacted concatenation of results for these variables.\n",
    "\n",
    "# ie. if we map 'N' and 'Y' to corresponding integers, we see values for 2020/21\n",
    "\n",
    "# so, let's fix these values\n",
    "\n",
    "for var in ['Solar Hot Water','Rainwater Tank']:\n",
    "    for year in ['2020','2021']:\n",
    "        dfs[year][var] = dfs[year][var].map({'N':0,'Y':1})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752578c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine the datasets!\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558d94b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Label factor variables\n",
    "factor_variable_labels = {\n",
    "'Permit Stage Number':{0:'no stages applicable',1:'stage 1',2:'stage 2'},\n",
    "'Material Code Floor':{20:'Concrete or stone',40:'Timber',80:'Other'},\n",
    "'Material Code Frame':{40:'Timber',60:'Steel',70:'Aluminium',80:'Other'},\n",
    "'Material Code Roof':{10:'Tiles',20:'Concrete or slate',30:'Fibre cement',60:'Steel',70:'Aluminium',80:'Other'},\n",
    "'Material Code Walls':{11:'Brick, double',12:'Brick, veneer',20:'Concrete or stone',30:'Fibre cement',40:'Timber',50:'Curtain glass',60:'Steel',70:'Aluminium',80:'Other'},\n",
    "'Solar Hot Water':{0:'No',1:'Yes'},\n",
    "'Rainwater Tank':{0:'No',1:'Yes',},\n",
    "'BASIS NOW':{1:'New building',2:'Re-erection',3:'Extension',4:'Alteration',5:'Change of Use',6:'Demolition',7:'Removal',8:'Other'},\n",
    "'BASIS Ownership Sector':{'P':'private','L':'Local Government','S':'State Government','C':'Commonwealth Government'},\n",
    "'BASIS Owner Builder':{0:'registered builder',-1:'owner builder', 2:'owner builder registered',np.nan:'non-domestic'}\n",
    "}\n",
    "\n",
    "for var in factor_variable_labels:\n",
    "    df[var] = df[var].map(factor_variable_labels[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d50122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Describe the combined data:\n",
    "df.describe().astype(np.int64).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8686e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in factor_variable_labels:\n",
    "    print(\"\")\n",
    "    print((100*(pd.crosstab(df[var],\n",
    "                      df['Year'],\n",
    "                      margins=True,\n",
    "                      margins_name='Total',\n",
    "                     normalize='columns'))).round(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4187a3d",
   "metadata": {},
   "source": [
    "# Spatial data - attempt 1, using AURIN API\n",
    "Long story short, this approach was abandoned as it became apparent that suburb boundaries from the 2016 census time point were not appropriate due to rezoning for new suburbs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d32d2",
   "metadata": {},
   "source": [
    "# Get ABS ASGS 2016 suburb data from AURIN open api https://aurin.org.au/resources/aurin-apis/\n",
    "suburbs = 'https://openapi.aurin.org.au//public/wfs?request=getFeature&version=1.0.0&outputFormat=json&typename=aurin:datasource-AU_Govt_ABS-UoM_AURIN_DB_GeoLevel_ssc_2016_aust'\n",
    "r = requests.get(suburbs)\n",
    "data = r.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24088687",
   "metadata": {},
   "source": [
    "gdf = gpd.GeoDataFrame.from_features(data['features'])\n",
    "gdf = gdf[gdf['state_name_2016']=='Victoria']\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f9ad8",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825732dd",
   "metadata": {},
   "source": [
    "gdf['Suburb'] = gdf.ssc_name_2016.str.rstrip(' (Vic.)')\n",
    "gdf[['ssc_name_2016','Suburb']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1091543c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# the data isn't quite cleaned... there's a postcode here... but just one, so that's nice!\n",
    "df['Suburb'] = df['Site Suburb'].str.rstrip(' VIC').str.title()\n",
    "df[['Site Suburb','Suburb']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86f8de",
   "metadata": {},
   "source": [
    "\n",
    "df_merge = df.merge(gdf, on = ['Suburb'], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f62ed53",
   "metadata": {},
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3b192",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Lets enumerate how many did and did not successfully match up with the official suburb data!\n",
    "df_merge['ssc_name_2016'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05349674",
   "metadata": {},
   "source": [
    "# As a percentage\n",
    "\n",
    "100*(df_merge['ssc_name_2016'].isna().value_counts())/len(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b7294",
   "metadata": {},
   "source": [
    "Approximately 5% of suburbs were unable to be matched, most likely due to inconsistencies in spelling and format. \n",
    "For the purposes of this analysis, this discrepency is acceptable, however with manual cleaning or similarity mapping this discrepency could be lessened. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934082e6",
   "metadata": {},
   "source": [
    "# Let's look at the top unmatched suburbs.\n",
    "\n",
    "# Looking at these, the top unmatched suburbs were gazetted after 2016 when this suburb data was current.\n",
    "# Let's find some more current suburb data!\n",
    "\n",
    "df_merge[df_merge['ssc_name_2016'].isna()]['Suburb'].sort_values().value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f75213",
   "metadata": {},
   "source": [
    "# Spatial data linkage using ASGS 2021 Suburbs and Localities data\n",
    "Suburbs and localities data from the 2021 Australia Statistical Geography Standard release were retrieved via the Australian Bureau of Statistics ESRI MapServer API in JSON (ESRIJSON) format.  Note that for this to be read a version of fiona with the appropriate driver for reading ESRIJSON (ie. > 1.8.5) is required; this analysis was run using fiona 1.8.20.  The environment.yml file used to create the Conda environment used for this analysis will be made available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a758cf",
   "metadata": {},
   "source": [
    "suburbs = \"https://geo.abs.gov.au/arcgis/rest/services/ASGS2021/SAL/MapServer/0/query?where=UPPER(STATE_NAME_2021)%20LIKE%20%27%25VICTORIA%25%27%20&text=&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&relationParam=&outFields=&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=7899&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&returnDistinctValues=false&resultOffset=&resultRecordCount=&f=json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c459ea4",
   "metadata": {},
   "source": [
    "# read in the suburbs\n",
    "gdf = gpd.read_file(suburbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f416d",
   "metadata": {},
   "source": [
    "# confirm the spatial coordinate reference system\n",
    "gdf.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf50c9",
   "metadata": {},
   "source": [
    "# list the available columns\n",
    "gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f3d42",
   "metadata": {},
   "source": [
    "# plot the 2021 Victorian suburb boundaries\n",
    "gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# That does not look right!  (its incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c43067",
   "metadata": {},
   "source": [
    "# Spatial attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "suburbs_url = \"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SAL_2021_AUST_GDA2020_SHP.zip\"\n",
    "suburbs_shp_zip = 'ABS_ASGS_2021_SAL.shp.zip'\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "if not os.path.exists(os.path.abspath(suburbs_shp_zip)):\n",
    "    download_url(suburbs_url,suburbs_shp_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf2cc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in the suburbs\n",
    "gdf = gpd.read_file(f\"zip://{os.path.abspath(suburbs_shp_zip)}\")\n",
    "gdf = gdf[gdf['STE_NAME21']=='Victoria']\n",
    "gdf.crs = {'init' :'epsg:7844'}\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f69859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.loc[:,'Suburb'] = gdf.SAL_NAME21.str.rstrip(' (Vic.)').copy()\n",
    "gdf[['SAL_NAME21','Suburb']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean planning permits data suburbs (following a previous in depth look to inform this replacement strategy)\n",
    "# # In order:\n",
    "#   - remove leading and trailing white space if any (doesn't appear to be, but could have been)    \n",
    "#   - remove a common unnecessary suffix that won't match\n",
    "#   - ensure title case (mostly helpful, but causes some complciations, eg with 'McCrae', but deal with later)\n",
    "df.loc[:,'Suburb'] = df['Site Suburb'] \\\n",
    "    .str.strip() \\\n",
    "    .str.rstrip(' VIC') \\\n",
    "    .str.title()\n",
    "\n",
    "df[['Site Suburb','Suburb']].sort_values('Suburb').head(20)\n",
    "# The building permits data isn't quite cleaned... there's a postcode here... but just one, so that's nice!  Also a few empties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the title case for \"Mc\" type suburbs includes uppercase following this (ie. McCrae, not Mccrae)\n",
    "df.loc[df['Suburb'].str.startswith('Mc', na=False),'Suburb'] = df.loc[df['Suburb'].str.startswith('Mc', na=False),'Suburb'].apply(lambda x: f\"{x[:2]}{x[2:].title()}\")\n",
    "\n",
    "df.loc[df['Suburb'].str.startswith('Mc', na=False),['Site Suburb','Suburb']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d1f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the permits data with digital boundaries for suburbs and localities\n",
    "gdf_suburbs = gdf[['SAL_NAME21','Suburb','geometry']].merge(df, on = ['Suburb'], how=\"right\")\n",
    "gdf_suburbs[['Suburb','geometry']].drop_duplicates().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd5cf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lets enumerate how many did and did not successfully match up with the official suburb data!\n",
    "print(f\"Suburbs not matched with geometry\\n\")\n",
    "print(f\"Counts:\\n{gdf_suburbs['SAL_NAME21'].isna().value_counts()}\\n\")\n",
    "print(f\"Percentages:\\n{100*(gdf_suburbs['SAL_NAME21'].isna().value_counts())/len(gdf_suburbs)}\")\n",
    "# About 1.4% not matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836a6d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the top unmatched suburbs -- many seem be due to ambiguities...\n",
    "gdf_suburbs[gdf_suburbs['SAL_NAME21'].isna()]['Suburb'].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcf7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(gdf_suburbs[gdf_suburbs['SAL_NAME21'].isna()]['Suburb'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Suburb']=='Newtown',['Site Suburb', 'Site Postcode',\n",
    "       'Municipal Name', 'Municipal Full Name', 'Region', 'Sub Region',\n",
    "       'Sub Region1']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_suburbs.loc[gdf_suburbs['SAL_NAME21'].isna()].apply(lambda x: f'{x[\"Suburb\"]} ({x[\"Municipal Name\"]} - Vic.)')\n",
    "\n",
    "#gdf_suburbs[gdf_suburbs['SAL_NAME21'].isna()]['Suburb','Site Suburb', 'Site Postcode',\n",
    "#       'Municipal Name', 'Municipal Full Name', 'Region', 'Sub Region',\n",
    "#       'Sub Region1']\n",
    "\n",
    "#df.reset_index(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34049732",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf[gdf.SAL_NAME21.str.startswith(\"Newtown\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70bcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf[gdf.SAL_NAME21.str.startswith(\"Hillside\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37143eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a constant as a non NA utility variable to use for aggregation\n",
    "gdf_suburbs['constant'] = 1\n",
    "# Aggregate by Year and Suburb, getting counts of permits by suburb for each year, and dropping any NA values\n",
    "suburb_year_counts = gdf[['SAL_NAME21','Suburb','geometry']].merge(gdf_suburbs.groupby(['Year','Suburb'])['constant'].sum().reset_index(), on = ['Suburb'], how=\"left\")\n",
    "suburb_year_counts.rename(columns={'constant':'Permits'},inplace=True)\n",
    "#suburb_year_counts = suburb_year_counts.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Display using geopandas\n",
    "for year in suburb_year_counts.Year.unique():\n",
    "    fig, ax = plt.subplots(1,1, figsize=(20,20))\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=-1) #resize the colorbar\n",
    "    suburb_year_counts.loc[suburb_year_counts['Year']==year].plot(\n",
    "        column='Permits', \n",
    "        ax=ax,\n",
    "        cax=cax,  \n",
    "        legend=True,\n",
    "        legend_kwds={'label': f\"Planning permits {year}\"})\n",
    "    #suburb_year_counts.geometry.boundary.plot(color='#BABABA', ax=ax, linewidth=0.3) #Add some borders to the geometries\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3be899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig = px.choropleth(suburb_year_counts,\n",
    "#                   locations=suburb_year_counts.index,\n",
    "#                   geojson=suburb_year_counts['geometry'].to_crs(epsg=4326).__geo_interface__,\n",
    "#                   animation_frame=suburb_year_counts['Year'],\n",
    "#                   color=suburb_year_counts[\"Permits\"])\n",
    "#fig.write_html('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the data for the map\n",
    "#data = go.Choropleth(\n",
    "#        geojson = suburb_year_counts['geometry'].__geo_interface__,             #this is your GeoJSON\n",
    "#        locations = suburb_year_counts.index,    #the index of this dataframe should align with the 'id' element in your geojson\n",
    "#        z = df_merged.percent_unemployed, #sets the color value\n",
    "#        text = df_merged.LGA_NAME20,    #sets text for each shape\n",
    "#        colorbar=dict(thickness=20, ticklen=3, tickformat='%',outlinewidth=0), #adjusts the format of the colorbar\n",
    "#        marker_line_width=1, marker_opacity=0.7, colorscale=\"Viridis\", #adjust format of the plot\n",
    "#        zmin=zmin, zmax=zmax,           #sets min and max of the colorbar\n",
    "#        hovertemplate = \"<b>%{text}</b><br>\" +\n",
    "#                    \"%{z:.0%}<br>\" +\n",
    "#                    \"<extra></extra>\")  # sets the format of the text shown when you hover over each shape\n",
    "#\n",
    "## Set the layout for the map\n",
    "#layout = go.Layout(\n",
    "#    title = {'text': f\"Population of Victoria, Australia\",\n",
    "#            'font': {'size':24}},       #format the plot title\n",
    "#    mapbox1 = dict(\n",
    "#        domain = {'x': [0, 1],'y': [0, 1]}, \n",
    "#        center = dict(lat=-36.5 , lon=145.5),\n",
    "#        accesstoken = MAPBOX_ACCESSTOKEN, \n",
    "#        zoom = 6),                      \n",
    "#    autosize=True,\n",
    "#    height=650,\n",
    "#    margin=dict(l=0, r=0, t=40, b=0))\n",
    "#\n",
    "## Generate the map\n",
    "#fig=go.Figure(data=data, layout=layout)\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# project to meters (GDA94 VicGrid 94, EPSG 3111), then simplify to nearest meter, and reproject to lat lon for plotting\n",
    "#suburb_year_counts.geometry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

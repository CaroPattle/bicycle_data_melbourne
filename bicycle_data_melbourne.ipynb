{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df4fbd5",
   "metadata": {},
   "source": [
    "# Bicycle data melbourne analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29df2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87e01f",
   "metadata": {},
   "source": [
    "## Data validation \n",
    "\n",
    "The bicycle data is delivered in a large number of CSV files, without an accompanying data dictionary.  To be sure the same columns are shared by all CSVs, such that they can be appended to a master file, we iterate over them and tally up the unique column combinations.  Ideally, the results will be a single combination of columns with a tally count the length of the number of CSV files.  Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b16054",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir ='../data'\n",
    "tally = pd.DataFrame(columns=[\"count\",\"len\"])\n",
    "counter = 0\n",
    "for subdir, dirs, files in tqdm(os.walk(rootdir)):\n",
    "    for file in files:\n",
    "        if ('.csv' in file) and ('.zip' not in file):\n",
    "            # read in CSV, if it contains records (which at least one doesn't!)\n",
    "            file_path = os.path.join(subdir,file)\n",
    "            if os.path.getsize(file_path) > 0:\n",
    "                df = pd.read_csv(os.path.join(subdir,file))\n",
    "                # store list of columns in variable df_columns as a string\n",
    "                df_columns = f\"{df.columns.to_list()}\"\n",
    "                # if CSV columns string is in the tally index, increment this\n",
    "                if df_columns in tally.index:\n",
    "                    tally[tally.index==df_columns] += 1\n",
    "                # otherwise add CSV columns string to the tally index\n",
    "                else:\n",
    "                    tally.loc[df_columns] = 1\n",
    "                # increment a counter; athough theoretically this should only sum to the sum of tallys!\n",
    "                counter+=1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "627d1e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['DATA_TYPE', 'TIS_DATA_REQUEST', 'SITE_XN_ROUTE', 'LOC_LEG', 'DATE', 'TIME', 'CLASS', 'LANE', 'SPEED', 'WHEELBASE', 'HEADWAY', 'GAP', 'AXLE', 'AXLE_GROUPING', 'RHO', 'VEHICLE', 'DIRECTION']</th>\n",
       "      <td>13229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    count\n",
       "['DATA_TYPE', 'TIS_DATA_REQUEST', 'SITE_XN_ROUT...  13229"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a0da80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(subdir,file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ecafb",
   "metadata": {},
   "source": [
    "## Creating a master dataframe\n",
    "\n",
    "Now that we know that all of the CSVs share the same column names, we will join the various files together to create a master dataframe to run the analysis on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3651e86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a274f14ad074496aa65c598d1fef9320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d9dc56bcd0454386a0146996fca6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Joining csv files...:   0%|          | 0/16054 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rootdir ='../data'\n",
    "csv_files = []\n",
    "\n",
    "for subdir, dirs, files in tqdm(os.walk(rootdir)):\n",
    "    for file in files:\n",
    "        if ('.csv' in file) and ('.zip' not in file):\n",
    "            # record filepaths of CSVs containing records\n",
    "            file_path = os.path.join(subdir,file)\n",
    "            if os.path.getsize(file_path) > 0:\n",
    "                csv_files.append(os.path.join(subdir,file))\n",
    "\n",
    "df = pd.concat([pd.read_csv(file) for file in tqdm(csv_files,desc=\"Joining csv files...\",unit=\"files\")])            \n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70add0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('master_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1771b",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Let's look at the summary statistics for the master dataframe! First we'll look at what type of data is included in each column. Then we can see can check the max/min values, and the distribution of the data, to see if there are any outlying data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a1749b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4925 entries, 0 to 4924\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   DATA_TYPE         4925 non-null   object \n",
      " 1   TIS_DATA_REQUEST  4925 non-null   int64  \n",
      " 2   SITE_XN_ROUTE     4925 non-null   int64  \n",
      " 3   LOC_LEG           4925 non-null   int64  \n",
      " 4   DATE              4925 non-null   object \n",
      " 5   TIME              4925 non-null   object \n",
      " 6   CLASS             4925 non-null   int64  \n",
      " 7   LANE              4925 non-null   int64  \n",
      " 8   SPEED             4925 non-null   float64\n",
      " 9   WHEELBASE         4925 non-null   float64\n",
      " 10  HEADWAY           4925 non-null   float64\n",
      " 11  GAP               4925 non-null   float64\n",
      " 12  AXLE              4925 non-null   int64  \n",
      " 13  AXLE_GROUPING     4925 non-null   int64  \n",
      " 14  RHO               4925 non-null   float64\n",
      " 15  VEHICLE           4925 non-null   object \n",
      " 16  DIRECTION         4925 non-null   object \n",
      " 17  source_file       4925 non-null   object \n",
      "dtypes: float64(5), int64(7), object(6)\n",
      "memory usage: 692.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking data types in each column\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02aefb02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIS_DATA_REQUEST</th>\n",
       "      <th>SITE_XN_ROUTE</th>\n",
       "      <th>LOC_LEG</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>LANE</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>WHEELBASE</th>\n",
       "      <th>HEADWAY</th>\n",
       "      <th>GAP</th>\n",
       "      <th>AXLE</th>\n",
       "      <th>AXLE_GROUPING</th>\n",
       "      <th>RHO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4925.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.000000</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>4925.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59443.482437</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.482437</td>\n",
       "      <td>18.764264</td>\n",
       "      <td>1.001401</td>\n",
       "      <td>473.021401</td>\n",
       "      <td>472.778518</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499742</td>\n",
       "      <td>7.449773</td>\n",
       "      <td>0.142950</td>\n",
       "      <td>2259.648522</td>\n",
       "      <td>2259.641277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59443.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59443.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59443.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>109.100000</td>\n",
       "      <td>108.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59444.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>362.800000</td>\n",
       "      <td>361.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>208.0</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>59444.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>35194.600000</td>\n",
       "      <td>35194.400000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TIS_DATA_REQUEST  SITE_XN_ROUTE       LOC_LEG   CLASS         LANE  \\\n",
       "count            4925.0         4925.0   4925.000000  4925.0  4925.000000   \n",
       "mean              208.0        10223.0  59443.482437    15.0     0.482437   \n",
       "std                 0.0            0.0      0.499742     0.0     0.499742   \n",
       "min               208.0        10223.0  59443.000000    15.0     0.000000   \n",
       "25%               208.0        10223.0  59443.000000    15.0     0.000000   \n",
       "50%               208.0        10223.0  59443.000000    15.0     0.000000   \n",
       "75%               208.0        10223.0  59444.000000    15.0     1.000000   \n",
       "max               208.0        10223.0  59444.000000    15.0     1.000000   \n",
       "\n",
       "             SPEED    WHEELBASE       HEADWAY           GAP    AXLE  \\\n",
       "count  4925.000000  4925.000000   4925.000000   4925.000000  4925.0   \n",
       "mean     18.764264     1.001401    473.021401    472.778518     2.0   \n",
       "std       7.449773     0.142950   2259.648522   2259.641277     0.0   \n",
       "min       1.400000     0.000000      0.000000      0.000000     2.0   \n",
       "25%      13.200000     1.000000      5.600000      5.400000     2.0   \n",
       "50%      18.500000     1.000000    109.100000    108.700000     2.0   \n",
       "75%      23.900000     1.100000    362.800000    361.700000     2.0   \n",
       "max     120.500000     4.000000  35194.600000  35194.400000     2.0   \n",
       "\n",
       "       AXLE_GROUPING          RHO  \n",
       "count         4925.0  4925.000000  \n",
       "mean             1.0     0.984083  \n",
       "std              0.0     0.081180  \n",
       "min              1.0     0.200000  \n",
       "25%              1.0     1.000000  \n",
       "50%              1.0     1.000000  \n",
       "75%              1.0     1.000000  \n",
       "max              1.0     1.200000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary statistics\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b25a6eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize('../data\\Bicycle_Volume_Speed_2020\\Black Rock - Bicycle volume data 2020\\IND_D5555_X32021.csv.20201228')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
